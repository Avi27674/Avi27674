{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxWR2mtIa2jaD9caXjsWyA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avi27674/Avi27674/blob/main/VGG_16_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing  required Library"
      ],
      "metadata": {
        "id": "5mcqEvkENDYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "V1jtLzJhNJIA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Mnist dataset"
      ],
      "metadata": {
        "id": "BEBsA4sGOa79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdILcGLHOiAM",
        "outputId": "20f9ce17-6635-4d67-98ad-9a3bd5d29ab5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the data: reshaping and normalizing the images"
      ],
      "metadata": {
        "id": "k0EfwC2tOtBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images=train_images.reshape((60000,28,28,1)).astype('float32')/255\n",
        "test_images=test_images.reshape((10000,28,28,1)).astype('float32')/255"
      ],
      "metadata": {
        "id": "qYZgE_iVO3Lm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resize images to 32x32"
      ],
      "metadata": {
        "id": "snudxrWuPci9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_resized = tf.image.resize(train_images,\n",
        "(32, 32))\n",
        "test_images_resized = tf.image.resize(test_images,\n",
        "(32, 32))"
      ],
      "metadata": {
        "id": "Vl-JikUXPoU-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Since VGG16/Mobilenet requires 3-channel input,\n",
        "we replicate the grayscale image across 3\n",
        "channels"
      ],
      "metadata": {
        "id": "4eYAUj1NP69l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_rgb =tf.image.grayscale_to_rgb(train_images_resized)\n",
        "test_images_rgb =tf.image.grayscale_to_rgb(test_images_resized)"
      ],
      "metadata": {
        "id": "pCQ3H3MYQDCI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert labels to categorical format(one-hot encoding)"
      ],
      "metadata": {
        "id": "E-ihuhqSQUn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)"
      ],
      "metadata": {
        "id": "9fBe_ICOQaGB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load a pretrained MobileNetV2 model without the classification layer"
      ],
      "metadata": {
        "id": "DASPJDLAQisN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False,\n",
        "input_shape=(32, 32, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcjtANz-QyLI",
        "outputId": "a88545b0-82f2-4844-d009-2d30d74876a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Freeze the pretrained layers"
      ],
      "metadata": {
        "id": "i7fi6bvLQ3zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "T7H01ndrQ8EI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add custom layers on top of the pre-trained model"
      ],
      "metadata": {
        "id": "j0oSRZJYQ33B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "base_model, # Use VGG16 as the feature extractor\n",
        "layers.Flatten(),layers.Dense(64, activation='relu'),layers.Dense(10, activation='softmax')])"
      ],
      "metadata": {
        "id": "j1ZjhVQ_RHsz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile the model"
      ],
      "metadata": {
        "id": "0NRPbCjyRcfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ropAv-GxRfgr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Evaluate"
      ],
      "metadata": {
        "id": "EZnOhkMuRnh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images_rgb, train_labels,\n",
        "epochs=5, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is-hnOP5Rp38",
        "outputId": "61d9b14d-87ad-445c-dff9-da2ad3fcb4c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.7368 - loss: 0.9195 - val_accuracy: 0.9292 - val_loss: 0.2521\n",
            "Epoch 2/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9344 - loss: 0.2275 - val_accuracy: 0.9463 - val_loss: 0.1756\n",
            "Epoch 3/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9513 - loss: 0.1649 - val_accuracy: 0.9549 - val_loss: 0.1479\n",
            "Epoch 4/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9564 - loss: 0.1414 - val_accuracy: 0.9578 - val_loss: 0.1318\n",
            "Epoch 5/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9640 - loss: 0.1201 - val_accuracy: 0.9582 - val_loss: 0.1269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model"
      ],
      "metadata": {
        "id": "PP5CH_s7Rx7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images_rgb,\n",
        "test_labels)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjkejC9ZR1Op",
        "outputId": "cc095c6d-377c-4aaf-a9f4-7ea1575fa06a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9567 - loss: 0.1300\n",
            "Test Accuracy: 0.9603999853134155\n"
          ]
        }
      ]
    }
  ]
}